{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1997)\n",
    "tf.random.set_seed(1997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(len(X_train), -1)\n",
    "y_train = y_train.reshape(len(y_train), -1)\n",
    "X_test = X_test.reshape(len(X_test), -1)\n",
    "y_test = y_test.reshape(len(y_test), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(float)/255\n",
    "X_test = X_test.astype(float)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = models.Sequential([\n",
    "            layers.Dense(128),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        self.layer2 = models.Sequential([\n",
    "            layers.Dense(2048),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.BatchNormalization(),\n",
    "            # BatchNormalization => 장점을 찾아보기\n",
    "            layers.ReLU()\n",
    "        ])\n",
    "        self.layer3 = models.Sequential([\n",
    "            layers.Dense(10),\n",
    "            layers.Softmax()\n",
    "        ])\n",
    "        \n",
    "    def call(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "DnnModel = DNN()\n",
    "DnnModel.build(input_shape = (512, 784))\n",
    "#메모리 소비가 200과 256이 동일 그러므 256사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "DnnModel.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#콜백함수\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "def scheduler(epoch,lr):\n",
    "    tf.print(f'learning rate : {lr:5f}')\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    elif epoch < 10:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.01)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler) \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = 'tmp_checkpoint.ckpt', \n",
    "                                                save_weights_only=True,\n",
    "                                                save_best_only=True,\n",
    "                                                monitor = 'val_loss',\n",
    "                                                verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "learning rate : 0.005827\n",
      "Epoch 1/20\n",
      "59392/60000 [============================>.] - ETA: 0s - loss: 0.2372 - accuracy: 0.9106\n",
      "Epoch 00001: val_loss improved from 0.33967 to 0.32851, saving model to tmp_checkpoint.ckpt\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2371 - accuracy: 0.9105 - val_loss: 0.3285 - val_accuracy: 0.8843\n",
      "learning rate : 0.005827\n",
      "Epoch 2/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2294 - accuracy: 0.9131\n",
      "Epoch 00002: val_loss did not improve from 0.32851\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2296 - accuracy: 0.9130 - val_loss: 0.3465 - val_accuracy: 0.8801\n",
      "learning rate : 0.005827\n",
      "Epoch 3/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2251 - accuracy: 0.9145\n",
      "Epoch 00003: val_loss did not improve from 0.32851\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2254 - accuracy: 0.9145 - val_loss: 0.3345 - val_accuracy: 0.8824\n",
      "learning rate : 0.005827\n",
      "Epoch 4/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.9151\n",
      "Epoch 00004: val_loss improved from 0.32851 to 0.32185, saving model to tmp_checkpoint.ckpt\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2246 - accuracy: 0.9151 - val_loss: 0.3218 - val_accuracy: 0.8871\n",
      "learning rate : 0.005827\n",
      "Epoch 5/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2204 - accuracy: 0.9168\n",
      "Epoch 00005: val_loss did not improve from 0.32185\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2203 - accuracy: 0.9168 - val_loss: 0.3539 - val_accuracy: 0.8718\n",
      "learning rate : 0.005827\n",
      "Epoch 6/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2156 - accuracy: 0.9186\n",
      "Epoch 00006: val_loss did not improve from 0.32185\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2155 - accuracy: 0.9187 - val_loss: 0.3234 - val_accuracy: 0.8843\n",
      "learning rate : 0.005273\n",
      "Epoch 7/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.9216\n",
      "Epoch 00007: val_loss did not improve from 0.32185\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2079 - accuracy: 0.9215 - val_loss: 0.3354 - val_accuracy: 0.8840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b8a3818320>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DnnModel.fit(X_train, y_train, callbacks=[earlystopping, lr_scheduler, checkpoint], batch_size=128, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 45us/sample - loss: 0.3354 - accuracy: 0.8840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3354127689957619, 0.884]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DnnModel.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hikeras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
