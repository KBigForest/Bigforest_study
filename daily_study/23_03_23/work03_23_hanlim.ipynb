{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "X_train_in = tf.expand_dims(X_train,-1)\n",
    "X_test_in = tf.expand_dims(X_test,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 28, 28, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.convolutions = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (3,3),input_shape = (28,28,1)),\n",
    "            tf.keras.layers.ReLU()\n",
    "        ])\n",
    "        self.pooling = tf.keras.Sequential([\n",
    "            tf.keras.layers.MaxPooling2D((2,2))\n",
    "        ])\n",
    "        self.densing = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(10),\n",
    "            tf.keras.layers.Softmax()\n",
    "        ])\n",
    "    def call(self, x):\n",
    "        x = self.convolutions(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.densing(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.build(input_shape=(128,28,28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam', loss = 'sparse_categorical_crossentropy', metrics =['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch,lr):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr* tf.math.sqrt(-0.1)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience = 3, verbose = 1, monitor = 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Do not pass inputs that mix Numpy arrays and TensorFlow tensors. You passed: x=tf.Tensor(\n[[[[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  ...\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]]\n\n\n [[[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  ...\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]]\n\n\n [[[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  ...\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]]\n\n\n ...\n\n\n [[[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  ...\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]]\n\n\n [[[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  ...\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]]\n\n\n [[[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  ...\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]]], shape=(60000, 28, 28, 1), dtype=float64); y=[9 0 0 ... 3 0 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-062603938c6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\dddf\\anaconda3\\envs\\hikeras\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\Users\\dddf\\anaconda3\\envs\\hikeras\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dddf\\anaconda3\\envs\\hikeras\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dddf\\anaconda3\\envs\\hikeras\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dddf\\anaconda3\\envs\\hikeras\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2358\u001b[0m     \u001b[0mis_compile_called\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2360\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compile_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2361\u001b[0m       \u001b[0mis_compile_called\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dddf\\anaconda3\\envs\\hikeras\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_compile_from_inputs\u001b[1;34m(self, all_inputs, target, orig_inputs, orig_target)\u001b[0m\n\u001b[0;32m   2592\u001b[0m                          \u001b[1;34m'TensorFlow tensors. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2593\u001b[0m                          \u001b[1;34m'You passed: x='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_inputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2594\u001b[1;33m                          '; y=' + str(orig_target))\n\u001b[0m\u001b[0;32m   2595\u001b[0m     is_dataset = isinstance(orig_inputs, (dataset_ops.DatasetV1,\n\u001b[0;32m   2596\u001b[0m                                           \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Do not pass inputs that mix Numpy arrays and TensorFlow tensors. You passed: x=tf.Tensor(\n[[[[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  ...\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]]\n\n\n [[[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  ...\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]]\n\n\n [[[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  ...\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]]\n\n\n ...\n\n\n [[[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  ...\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]]\n\n\n [[[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  ...\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]]\n\n\n [[[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  ...\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]\n\n  [[0.]\n   [0.]\n   [0.]\n   ...\n   [0.]\n   [0.]\n   [0.]]]], shape=(60000, 28, 28, 1), dtype=float64); y=[9 0 0 ... 3 0 5]"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_in, y_train, epochs=20, callbacks=[lr_scheduler, early_stopping], validation_data = (), batch_size= 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hikeras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
