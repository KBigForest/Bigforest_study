{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모듈 로딩\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horsepower    398 non-null    object \n",
      " 4   weight        398 non-null    int64  \n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model year    398 non-null    int64  \n",
      " 7   origin        398 non-null    int64  \n",
      " 8   car name      398 non-null    object \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "mpg = pd.read_csv('../dataset/auto-mpg.csv')\n",
    "\n",
    "mpg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 0\n",
      "0값?:               mpg   cylinders  displacement       weight  acceleration  \\\n",
      "count  398.000000  398.000000    398.000000   398.000000    398.000000   \n",
      "mean    23.514573    5.454774    193.425879  2970.424623     15.568090   \n",
      "std      7.815984    1.701004    104.269838   846.841774      2.757689   \n",
      "min      9.000000    3.000000     68.000000  1613.000000      8.000000   \n",
      "25%     17.500000    4.000000    104.250000  2223.750000     13.825000   \n",
      "50%     23.000000    4.000000    148.500000  2803.500000     15.500000   \n",
      "75%     29.000000    8.000000    262.000000  3608.000000     17.175000   \n",
      "max     46.600000    8.000000    455.000000  5140.000000     24.800000   \n",
      "\n",
      "       model year      origin  \n",
      "count  398.000000  398.000000  \n",
      "mean    76.010050    1.572864  \n",
      "std      3.697627    0.802055  \n",
      "min     70.000000    1.000000  \n",
      "25%     73.000000    1.000000  \n",
      "50%     76.000000    1.000000  \n",
      "75%     79.000000    2.000000  \n",
      "max     82.000000    3.000000  \n"
     ]
    }
   ],
   "source": [
    "print(f'결측치 {mpg.isnull().sum().sum()}')\n",
    "print(f'0값?: {mpg.describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mpg.rename(columns={'car name': 'car_name'}, inplace=True)\n",
    "mpg['origin'] = mpg['origin'].astype('category')\n",
    "mpg_copy= mpg.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpg\n",
      "<bound method Series.unique of 0      18.0\n",
      "1      15.0\n",
      "2      18.0\n",
      "3      16.0\n",
      "4      17.0\n",
      "       ... \n",
      "393    27.0\n",
      "394    44.0\n",
      "395    32.0\n",
      "396    28.0\n",
      "397    31.0\n",
      "Name: mpg, Length: 398, dtype: float64>\n",
      "cylinders\n",
      "<bound method Series.unique of 0      8\n",
      "1      8\n",
      "2      8\n",
      "3      8\n",
      "4      8\n",
      "      ..\n",
      "393    4\n",
      "394    4\n",
      "395    4\n",
      "396    4\n",
      "397    4\n",
      "Name: cylinders, Length: 398, dtype: int64>\n",
      "displacement\n",
      "<bound method Series.unique of 0      307.0\n",
      "1      350.0\n",
      "2      318.0\n",
      "3      304.0\n",
      "4      302.0\n",
      "       ...  \n",
      "393    140.0\n",
      "394     97.0\n",
      "395    135.0\n",
      "396    120.0\n",
      "397    119.0\n",
      "Name: displacement, Length: 398, dtype: float64>\n",
      "horsepower\n",
      "<bound method Series.unique of 0      130\n",
      "1      165\n",
      "2      150\n",
      "3      150\n",
      "4      140\n",
      "      ... \n",
      "393     86\n",
      "394     52\n",
      "395     84\n",
      "396     79\n",
      "397     82\n",
      "Name: horsepower, Length: 398, dtype: object>\n",
      "weight\n",
      "<bound method Series.unique of 0      3504\n",
      "1      3693\n",
      "2      3436\n",
      "3      3433\n",
      "4      3449\n",
      "       ... \n",
      "393    2790\n",
      "394    2130\n",
      "395    2295\n",
      "396    2625\n",
      "397    2720\n",
      "Name: weight, Length: 398, dtype: int64>\n",
      "acceleration\n",
      "<bound method Series.unique of 0      12.0\n",
      "1      11.5\n",
      "2      11.0\n",
      "3      12.0\n",
      "4      10.5\n",
      "       ... \n",
      "393    15.6\n",
      "394    24.6\n",
      "395    11.6\n",
      "396    18.6\n",
      "397    19.4\n",
      "Name: acceleration, Length: 398, dtype: float64>\n",
      "model year\n",
      "<bound method Series.unique of 0      70\n",
      "1      70\n",
      "2      70\n",
      "3      70\n",
      "4      70\n",
      "       ..\n",
      "393    82\n",
      "394    82\n",
      "395    82\n",
      "396    82\n",
      "397    82\n",
      "Name: model year, Length: 398, dtype: int64>\n",
      "origin\n",
      "<bound method Series.unique of 0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "393    1\n",
      "394    2\n",
      "395    1\n",
      "396    1\n",
      "397    1\n",
      "Name: origin, Length: 398, dtype: category\n",
      "Categories (3, int64): [1, 2, 3]>\n",
      "car_name\n",
      "<bound method Series.unique of 0      chevrolet chevelle malibu\n",
      "1              buick skylark 320\n",
      "2             plymouth satellite\n",
      "3                  amc rebel sst\n",
      "4                    ford torino\n",
      "                 ...            \n",
      "393              ford mustang gl\n",
      "394                    vw pickup\n",
      "395                dodge rampage\n",
      "396                  ford ranger\n",
      "397                   chevy s-10\n",
      "Name: car_name, Length: 398, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "for col in mpg.columns:\n",
    "    print(f'{col}')\n",
    "    print(f'{mpg[col].unique}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "#같은 차종의 마력의 평균으로 '?'대체\n",
    "ques_car_name=mpg[mpg['horsepower']== '?'].car_name\n",
    "mean_list=[]\n",
    "\n",
    "x1 = mpg[mpg['car_name']==ques_car_name.iloc[0]].horsepower[1:].astype('int').mean()\n",
    "x2 = mpg[mpg['car_name']==ques_car_name.iloc[1]].horsepower[mpg[mpg['car_name']==ques_car_name.iloc[1]].horsepower != '?'].astype('int').mean()\n",
    "mpg.loc[32,'horsepower']= x1\n",
    "mpg.loc[126,'horsepower']=x2\n",
    "mpg.drop(mpg[mpg['horsepower']=='?'].index, inplace=True)\n",
    "mpg['horsepower'].value_counts()\n",
    "mpg['horsepower'] = mpg['horsepower'].astype('int64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 394 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   mpg           394 non-null    float64 \n",
      " 1   cylinders     394 non-null    int64   \n",
      " 2   displacement  394 non-null    float64 \n",
      " 3   horsepower    394 non-null    int64   \n",
      " 4   weight        394 non-null    int64   \n",
      " 5   acceleration  394 non-null    float64 \n",
      " 6   model year    394 non-null    int64   \n",
      " 7   origin        394 non-null    category\n",
      " 8   car_name      394 non-null    object  \n",
      "dtypes: category(1), float64(3), int64(4), object(1)\n",
      "memory usage: 28.2+ KB\n"
     ]
    }
   ],
   "source": [
    "mpg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>140.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>97.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>135.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>120.0</td>\n",
       "      <td>79</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>119.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     displacement  horsepower  weight  acceleration  model year\n",
       "0           307.0         130    3504          12.0          70\n",
       "1           350.0         165    3693          11.5          70\n",
       "2           318.0         150    3436          11.0          70\n",
       "3           304.0         150    3433          12.0          70\n",
       "4           302.0         140    3449          10.5          70\n",
       "..            ...         ...     ...           ...         ...\n",
       "393         140.0          86    2790          15.6          82\n",
       "394          97.0          52    2130          24.6          82\n",
       "395         135.0          84    2295          11.6          82\n",
       "396         120.0          79    2625          18.6          82\n",
       "397         119.0          82    2720          19.4          82\n",
       "\n",
       "[394 rows x 5 columns]"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg[mpg.columns[2:-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.081071</td>\n",
       "      <td>0.668219</td>\n",
       "      <td>0.624255</td>\n",
       "      <td>-1.290037</td>\n",
       "      <td>-1.620283</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.493114</td>\n",
       "      <td>1.580208</td>\n",
       "      <td>0.847271</td>\n",
       "      <td>-1.471537</td>\n",
       "      <td>-1.620283</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.186478</td>\n",
       "      <td>1.189356</td>\n",
       "      <td>0.544017</td>\n",
       "      <td>-1.653038</td>\n",
       "      <td>-1.620283</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.052324</td>\n",
       "      <td>1.189356</td>\n",
       "      <td>0.540477</td>\n",
       "      <td>-1.290037</td>\n",
       "      <td>-1.620283</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.033159</td>\n",
       "      <td>0.928787</td>\n",
       "      <td>0.559357</td>\n",
       "      <td>-1.834539</td>\n",
       "      <td>-1.620283</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>-0.720418</td>\n",
       "      <td>-0.582509</td>\n",
       "      <td>-0.300846</td>\n",
       "      <td>1.396173</td>\n",
       "      <td>1.640977</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     displacement  horsepower    weight  acceleration  model year   mpg\n",
       "0        1.081071    0.668219  0.624255     -1.290037   -1.620283  18.0\n",
       "1        1.493114    1.580208  0.847271     -1.471537   -1.620283  15.0\n",
       "2        1.186478    1.189356  0.544017     -1.653038   -1.620283  18.0\n",
       "3        1.052324    1.189356  0.540477     -1.290037   -1.620283  16.0\n",
       "4        1.033159    0.928787  0.559357     -1.834539   -1.620283  17.0\n",
       "..            ...         ...       ...           ...         ...   ...\n",
       "393     -0.720418   -0.582509 -0.300846      1.396173    1.640977  27.0\n",
       "394           NaN         NaN       NaN           NaN         NaN  44.0\n",
       "395           NaN         NaN       NaN           NaN         NaN  32.0\n",
       "396           NaN         NaN       NaN           NaN         NaN  28.0\n",
       "397           NaN         NaN       NaN           NaN         NaN  31.0\n",
       "\n",
       "[398 rows x 6 columns]"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#표준화 데이터\n",
    "ss_data = StandardScaler()\n",
    "\n",
    "mpg_df = ss_data.fit_transform(mpg[mpg.columns[2:-2]])\n",
    "mpg_df = pd.DataFrame(mpg_df,columns=mpg.columns[2:-2])\n",
    "mpg_df\n",
    "mpg_df = pd.concat([mpg_df, mpg['mpg']], axis=1)\n",
    "mpg_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1]단순 선형회귀\n",
    "- 피쳐: 무게(weight)\n",
    "- 타겟: 연비(mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950823</td>\n",
       "      <td>0.842983</td>\n",
       "      <td>0.897527</td>\n",
       "      <td>-0.504683</td>\n",
       "      <td>-0.345647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.950823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897257</td>\n",
       "      <td>0.932994</td>\n",
       "      <td>-0.543800</td>\n",
       "      <td>-0.369855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>0.842983</td>\n",
       "      <td>0.897257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864538</td>\n",
       "      <td>-0.689196</td>\n",
       "      <td>-0.416361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>0.897527</td>\n",
       "      <td>0.932994</td>\n",
       "      <td>0.864538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.416839</td>\n",
       "      <td>-0.309120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>-0.504683</td>\n",
       "      <td>-0.543800</td>\n",
       "      <td>-0.689196</td>\n",
       "      <td>-0.416839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model year</th>\n",
       "      <td>-0.345647</td>\n",
       "      <td>-0.369855</td>\n",
       "      <td>-0.416361</td>\n",
       "      <td>-0.309120</td>\n",
       "      <td>0.290316</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cylinders  displacement  horsepower    weight  acceleration  \\\n",
       "cylinders      1.000000      0.950823    0.842983  0.897527     -0.504683   \n",
       "displacement   0.950823      1.000000    0.897257  0.932994     -0.543800   \n",
       "horsepower     0.842983      0.897257    1.000000  0.864538     -0.689196   \n",
       "weight         0.897527      0.932994    0.864538  1.000000     -0.416839   \n",
       "acceleration  -0.504683     -0.543800   -0.689196 -0.416839      1.000000   \n",
       "model year    -0.345647     -0.369855   -0.416361 -0.309120      0.290316   \n",
       "\n",
       "              model year  \n",
       "cylinders      -0.345647  \n",
       "displacement   -0.369855  \n",
       "horsepower     -0.416361  \n",
       "weight         -0.309120  \n",
       "acceleration    0.290316  \n",
       "model year      1.000000  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.483947</td>\n",
       "      <td>1.077290</td>\n",
       "      <td>0.664133</td>\n",
       "      <td>0.620540</td>\n",
       "      <td>-1.285258</td>\n",
       "      <td>-1.625315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.483947</td>\n",
       "      <td>1.488732</td>\n",
       "      <td>1.574594</td>\n",
       "      <td>0.843334</td>\n",
       "      <td>-1.466724</td>\n",
       "      <td>-1.625315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.483947</td>\n",
       "      <td>1.182542</td>\n",
       "      <td>1.184397</td>\n",
       "      <td>0.540382</td>\n",
       "      <td>-1.648189</td>\n",
       "      <td>-1.625315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.483947</td>\n",
       "      <td>1.048584</td>\n",
       "      <td>1.184397</td>\n",
       "      <td>0.536845</td>\n",
       "      <td>-1.285258</td>\n",
       "      <td>-1.625315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.483947</td>\n",
       "      <td>1.029447</td>\n",
       "      <td>0.924265</td>\n",
       "      <td>0.555706</td>\n",
       "      <td>-1.829655</td>\n",
       "      <td>-1.625315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>-0.864014</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>-0.480448</td>\n",
       "      <td>-0.221125</td>\n",
       "      <td>0.021294</td>\n",
       "      <td>1.636410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>-0.864014</td>\n",
       "      <td>-0.932079</td>\n",
       "      <td>-1.364896</td>\n",
       "      <td>-0.999134</td>\n",
       "      <td>3.287676</td>\n",
       "      <td>1.636410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>-0.864014</td>\n",
       "      <td>-0.568479</td>\n",
       "      <td>-0.532474</td>\n",
       "      <td>-0.804632</td>\n",
       "      <td>-1.430430</td>\n",
       "      <td>1.636410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>-0.864014</td>\n",
       "      <td>-0.712005</td>\n",
       "      <td>-0.662540</td>\n",
       "      <td>-0.415627</td>\n",
       "      <td>1.110088</td>\n",
       "      <td>1.636410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>-0.864014</td>\n",
       "      <td>-0.721574</td>\n",
       "      <td>-0.584501</td>\n",
       "      <td>-0.303641</td>\n",
       "      <td>1.400433</td>\n",
       "      <td>1.636410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cylinders  displacement  horsepower    weight  acceleration  model year\n",
       "0     1.483947      1.077290    0.664133  0.620540     -1.285258   -1.625315\n",
       "1     1.483947      1.488732    1.574594  0.843334     -1.466724   -1.625315\n",
       "2     1.483947      1.182542    1.184397  0.540382     -1.648189   -1.625315\n",
       "3     1.483947      1.048584    1.184397  0.536845     -1.285258   -1.625315\n",
       "4     1.483947      1.029447    0.924265  0.555706     -1.829655   -1.625315\n",
       "..         ...           ...         ...       ...           ...         ...\n",
       "387  -0.864014     -0.520637   -0.480448 -0.221125      0.021294    1.636410\n",
       "388  -0.864014     -0.932079   -1.364896 -0.999134      3.287676    1.636410\n",
       "389  -0.864014     -0.568479   -0.532474 -0.804632     -1.430430    1.636410\n",
       "390  -0.864014     -0.712005   -0.662540 -0.415627      1.110088    1.636410\n",
       "391  -0.864014     -0.721574   -0.584501 -0.303641      1.400433    1.636410\n",
       "\n",
       "[392 rows x 6 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mpg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.777618</td>\n",
       "      <td>-0.805127</td>\n",
       "      <td>-0.778427</td>\n",
       "      <td>-0.832244</td>\n",
       "      <td>0.423329</td>\n",
       "      <td>0.580541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>-0.777618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950823</td>\n",
       "      <td>0.842983</td>\n",
       "      <td>0.897527</td>\n",
       "      <td>-0.504683</td>\n",
       "      <td>-0.345647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>-0.805127</td>\n",
       "      <td>0.950823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897257</td>\n",
       "      <td>0.932994</td>\n",
       "      <td>-0.543800</td>\n",
       "      <td>-0.369855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>-0.778427</td>\n",
       "      <td>0.842983</td>\n",
       "      <td>0.897257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864538</td>\n",
       "      <td>-0.689196</td>\n",
       "      <td>-0.416361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.832244</td>\n",
       "      <td>0.897527</td>\n",
       "      <td>0.932994</td>\n",
       "      <td>0.864538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.416839</td>\n",
       "      <td>-0.309120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>0.423329</td>\n",
       "      <td>-0.504683</td>\n",
       "      <td>-0.543800</td>\n",
       "      <td>-0.689196</td>\n",
       "      <td>-0.416839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model year</th>\n",
       "      <td>0.580541</td>\n",
       "      <td>-0.345647</td>\n",
       "      <td>-0.369855</td>\n",
       "      <td>-0.416361</td>\n",
       "      <td>-0.309120</td>\n",
       "      <td>0.290316</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mpg  cylinders  displacement  horsepower    weight  \\\n",
       "mpg           1.000000  -0.777618     -0.805127   -0.778427 -0.832244   \n",
       "cylinders    -0.777618   1.000000      0.950823    0.842983  0.897527   \n",
       "displacement -0.805127   0.950823      1.000000    0.897257  0.932994   \n",
       "horsepower   -0.778427   0.842983      0.897257    1.000000  0.864538   \n",
       "weight       -0.832244   0.897527      0.932994    0.864538  1.000000   \n",
       "acceleration  0.423329  -0.504683     -0.543800   -0.689196 -0.416839   \n",
       "model year    0.580541  -0.345647     -0.369855   -0.416361 -0.309120   \n",
       "\n",
       "              acceleration  model year  \n",
       "mpg               0.423329    0.580541  \n",
       "cylinders        -0.504683   -0.345647  \n",
       "displacement     -0.543800   -0.369855  \n",
       "horsepower       -0.689196   -0.416361  \n",
       "weight           -0.416839   -0.309120  \n",
       "acceleration      1.000000    0.290316  \n",
       "model year        0.290316    1.000000  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cylinders와 mpg\n",
      "회귀계수 [[-6.03928626]], 상수 [23.25130611]\n",
      "MSE = 24.065\n",
      "R^2 = 0.608\n",
      "\n",
      "displacement와 mpg\n",
      "회귀계수 [[-6.19676262]], 상수 [23.31257045]\n",
      "MSE = 20.614\n",
      "R^2 = 0.664\n",
      "\n",
      "horsepower와 mpg\n",
      "회귀계수 [[-5.94827009]], 상수 [23.40678343]\n",
      "MSE = 21.672\n",
      "R^2 = 0.647\n",
      "\n",
      "weight와 mpg\n",
      "회귀계수 [[-6.4240011]], 상수 [23.37642931]\n",
      "MSE = 19.716\n",
      "R^2 = 0.679\n",
      "\n",
      "acceleration와 mpg\n",
      "회귀계수 [[3.10692766]], 상수 [23.26207354]\n",
      "MSE = 45.29\n",
      "R^2 = 0.262\n",
      "\n",
      "model year와 mpg\n",
      "회귀계수 [[4.48473529]], 상수 [23.21896917]\n",
      "MSE = 39.459\n",
      "R^2 = 0.357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in mpg_df.columns:\n",
    "    mpg_data = np.array(mpg_df[i]).reshape(-1, 1)\n",
    "    mpg_target = np.array(mpg['mpg']).reshape(-1, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(mpg_data, mpg_target, test_size=0.2, random_state=102)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    #MSE\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'{i}와 mpg')\n",
    "    print(f'회귀계수 {lr.coef_}, 상수 {lr.intercept_}')\n",
    "    print(f'MSE = {round(mse,3)}')\n",
    "    print(f'R^2 = {round(r2,3)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgin_dummy = pd.get_dummies(mpg['origin'], prefix='origin')\n",
    "model_year = pd.get_dummies(mpg['model year'], prefix='model year')\n",
    "cylinders = pd.get_dummies(mpg['cylinders'], prefix='cylinders')\n",
    "mpg_df = pd.concat([mpg_df, cylinders], axis=1)\n",
    "mpg_df = pd.concat([mpg_df, model_year], axis=1)\n",
    "mpg_df = pd.concat([mpg_df, orgin_dummy], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.drop(['cylinders','model year', 'origin', 'car_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year_70</th>\n",
       "      <th>model year_71</th>\n",
       "      <th>model year_72</th>\n",
       "      <th>model year_73</th>\n",
       "      <th>model year_74</th>\n",
       "      <th>...</th>\n",
       "      <th>model year_81</th>\n",
       "      <th>model year_82</th>\n",
       "      <th>origin_1</th>\n",
       "      <th>origin_2</th>\n",
       "      <th>origin_3</th>\n",
       "      <th>cylinders_3</th>\n",
       "      <th>cylinders_4</th>\n",
       "      <th>cylinders_5</th>\n",
       "      <th>cylinders_6</th>\n",
       "      <th>cylinders_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  displacement  horsepower  weight  acceleration  model year_70  \\\n",
       "0    18.0         307.0         130    3504          12.0              1   \n",
       "1    15.0         350.0         165    3693          11.5              1   \n",
       "2    18.0         318.0         150    3436          11.0              1   \n",
       "3    16.0         304.0         150    3433          12.0              1   \n",
       "4    17.0         302.0         140    3449          10.5              1   \n",
       "..    ...           ...         ...     ...           ...            ...   \n",
       "393  27.0         140.0          86    2790          15.6              0   \n",
       "394  44.0          97.0          52    2130          24.6              0   \n",
       "395  32.0         135.0          84    2295          11.6              0   \n",
       "396  28.0         120.0          79    2625          18.6              0   \n",
       "397  31.0         119.0          82    2720          19.4              0   \n",
       "\n",
       "     model year_71  model year_72  model year_73  model year_74  ...  \\\n",
       "0                0              0              0              0  ...   \n",
       "1                0              0              0              0  ...   \n",
       "2                0              0              0              0  ...   \n",
       "3                0              0              0              0  ...   \n",
       "4                0              0              0              0  ...   \n",
       "..             ...            ...            ...            ...  ...   \n",
       "393              0              0              0              0  ...   \n",
       "394              0              0              0              0  ...   \n",
       "395              0              0              0              0  ...   \n",
       "396              0              0              0              0  ...   \n",
       "397              0              0              0              0  ...   \n",
       "\n",
       "     model year_81  model year_82  origin_1  origin_2  origin_3  cylinders_3  \\\n",
       "0                0              0         1         0         0            0   \n",
       "1                0              0         1         0         0            0   \n",
       "2                0              0         1         0         0            0   \n",
       "3                0              0         1         0         0            0   \n",
       "4                0              0         1         0         0            0   \n",
       "..             ...            ...       ...       ...       ...          ...   \n",
       "393              0              1         1         0         0            0   \n",
       "394              0              1         0         1         0            0   \n",
       "395              0              1         1         0         0            0   \n",
       "396              0              1         1         0         0            0   \n",
       "397              0              1         1         0         0            0   \n",
       "\n",
       "     cylinders_4  cylinders_5  cylinders_6  cylinders_8  \n",
       "0              0            0            0            1  \n",
       "1              0            0            0            1  \n",
       "2              0            0            0            1  \n",
       "3              0            0            0            1  \n",
       "4              0            0            0            1  \n",
       "..           ...          ...          ...          ...  \n",
       "393            1            0            0            0  \n",
       "394            1            0            0            0  \n",
       "395            1            0            0            0  \n",
       "396            1            0            0            0  \n",
       "397            1            0            0            0  \n",
       "\n",
       "[392 rows x 39 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2]폴리노미얼 회귀\n",
    "- 피처: displacement\n",
    "- target: 연비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cylinders의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 1의 회귀계수는 [[-6.06]]\n",
      "MSE는 29.66\n",
      "\n",
      "cylinders의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 2의 회귀계수는 [[-6.41  0.69]]\n",
      "MSE는 29.63\n",
      "\n",
      "cylinders의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 3의 회귀계수는 [[-12.47  -3.05   4.96]]\n",
      "MSE는 27.31\n",
      "\n",
      "cylinders의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 5의 회귀계수는 [[ 3.30665679e+11 -2.47362766e+12 -3.05220542e+12  1.06149441e+12\n",
      "   1.32998199e+12]]\n",
      "MSE는 28.43\n",
      "\n",
      "cylinders의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 10의 회귀계수는 [[-1.46825551e+10  3.70850043e+11 -2.99599322e+10 -2.36610945e+11\n",
      "   7.44927678e+11 -1.37621801e+12  1.95601145e+12  5.63922879e+12\n",
      "  -9.99550141e+11 -2.29628227e+12]]\n",
      "MSE는 27.93\n",
      "\n",
      "displacement의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 1의 회귀계수는 [[-6.28]]\n",
      "MSE는 27.30\n",
      "\n",
      "displacement의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 2의 회귀계수는 [[-7.56  1.84]]\n",
      "MSE는 24.60\n",
      "\n",
      "displacement의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 3의 회귀계수는 [[-7.26  2.27 -0.27]]\n",
      "MSE는 24.91\n",
      "\n",
      "displacement의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 5의 회귀계수는 [[-7.14  3.21 -0.51 -0.59  0.22]]\n",
      "MSE는 25.46\n",
      "\n",
      "displacement의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 10의 회귀계수는 [[-10.51   6.93  22.48 -28.11 -27.24  42.86  -1.44 -17.36   8.14  -1.13]]\n",
      "MSE는 23.33\n",
      "\n",
      "horsepower의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 1의 회귀계수는 [[-6.07]]\n",
      "MSE는 31.45\n",
      "\n",
      "horsepower의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 2의 회귀계수는 [[-8.04  1.82]]\n",
      "MSE는 24.35\n",
      "\n",
      "horsepower의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 3의 회귀계수는 [[-7.87  2.08 -0.12]]\n",
      "MSE는 24.35\n",
      "\n",
      "horsepower의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 5의 회귀계수는 [[-8.61  4.51  0.19 -1.18  0.28]]\n",
      "MSE는 23.57\n",
      "\n",
      "horsepower의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 10의 회귀계수는 [[-5.12  5.8  -6.78 -2.78  4.35  0.51 -1.03 -0.04  0.14 -0.02]]\n",
      "MSE는 23.31\n",
      "\n",
      "weight의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 1의 회귀계수는 [[-6.49]]\n",
      "MSE는 25.02\n",
      "\n",
      "weight의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 2의 회귀계수는 [[-7.12  1.22]]\n",
      "MSE는 23.47\n",
      "\n",
      "weight의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 3의 회귀계수는 [[-7.14  1.21  0.01]]\n",
      "MSE는 23.87\n",
      "\n",
      "weight의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 5의 회귀계수는 [[-7.1   2.21 -0.21 -0.49  0.17]]\n",
      "MSE는 24.12\n",
      "\n",
      "weight의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 10의 회귀계수는 [[-7.93 -4.7   5.65 10.62 -9.5  -5.11  5.55  0.16 -1.02  0.21]]\n",
      "MSE는 24.21\n",
      "\n",
      "acceleration의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 1의 회귀계수는 [[3.3]]\n",
      "MSE는 60.68\n",
      "\n",
      "acceleration의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 2의 회귀계수는 [[ 3.48 -0.62]]\n",
      "MSE는 59.38\n",
      "\n",
      "acceleration의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 3의 회귀계수는 [[ 3.1  -0.7   0.12]]\n",
      "MSE는 61.86\n",
      "\n",
      "acceleration의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 5의 회귀계수는 [[ 3.28 -2.37  0.19  0.3  -0.04]]\n",
      "MSE는 61.13\n",
      "\n",
      "acceleration의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 10의 회귀계수는 [[ 2.47 -5.26  1.91  2.67 -0.89 -0.63  0.14  0.07 -0.01 -0.  ]]\n",
      "MSE는 178.81\n",
      "\n",
      "model year의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 1의 회귀계수는 [[4.53]]\n",
      "MSE는 47.40\n",
      "\n",
      "model year의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 2의 회귀계수는 [[4.5  1.49]]\n",
      "MSE는 38.73\n",
      "\n",
      "model year의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 3의 회귀계수는 [[ 5.11  1.5  -0.33]]\n",
      "MSE는 46.26\n",
      "\n",
      "model year의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 5의 회귀계수는 [[ 4.33  3.89  0.96 -0.91 -0.39]]\n",
      "MSE는 593.62\n",
      "\n",
      "model year의 플리노미얼 회귀 타겟은 MPG\n",
      "Degree 10의 회귀계수는 [[   4.51   28.49  -15.44 -110.45   37.38  145.77  -24.81  -73.36    4.84\n",
      "    12.3 ]]\n",
      "MSE는 19736809.42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mpg_data, mpg_data, test_size=0.2, random_state=102)\n",
    "\n",
    "degree = [1,2,3,5,10]\n",
    "for i in mpg_df.columns:\n",
    "    for j in range(len(degree)):\n",
    "        mpg_data = np.array(mpg_df[i]).reshape(-1, 1)\n",
    "        mpg_target = np.array(mpg['mpg']).reshape(-1, 1)\n",
    "\n",
    "        poly_feat = PolynomialFeatures(degree=degree[j],include_bias=False)\n",
    "        lr = LinearRegression()\n",
    "        pipeline = Pipeline([('poly',poly_feat),('lr',lr)])\n",
    "        pipeline.fit(mpg_data,mpg_target)\n",
    "        \n",
    "        score = cross_val_score(pipeline,mpg_data, mpg_target, cv=5, scoring= 'neg_mean_squared_error')\n",
    "        coef = pipeline.named_steps['lr'].coef_\n",
    "        print(f'{i}의 플리노미얼 회귀 타겟은 MPG')\n",
    "        print(f'Degree {degree[j]}의 회귀계수는 {np.round(coef,2)}')\n",
    "        print(f'MSE는 {-1*np.mean(score):.2f}')\n",
    "        print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3]릿지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "#더미값 생성\n",
    "orgin_dummy = pd.get_dummies(mpg['origin'], prefix='origin')\n",
    "model_year = pd.get_dummies(mpg['model year'], prefix='model year')\n",
    "cylinders = pd.get_dummies(mpg['cylinders'], prefix='cylinders')\n",
    "mpg_df = pd.concat([mpg_df, cylinders], axis=1)\n",
    "mpg_df = pd.concat([mpg_df, model_year], axis=1)\n",
    "mpg_df = pd.concat([mpg_df, orgin_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "displacement     0\n",
       "horsepower       0\n",
       "weight           0\n",
       "acceleration     0\n",
       "model year       0\n",
       "mpg              0\n",
       "cylinders_3      0\n",
       "cylinders_4      0\n",
       "cylinders_5      0\n",
       "cylinders_6      0\n",
       "cylinders_8      0\n",
       "model year_70    0\n",
       "model year_71    0\n",
       "model year_72    0\n",
       "model year_73    0\n",
       "model year_74    0\n",
       "model year_75    0\n",
       "model year_76    0\n",
       "model year_77    0\n",
       "model year_78    0\n",
       "model year_79    0\n",
       "model year_80    0\n",
       "model year_81    0\n",
       "model year_82    0\n",
       "origin_1         0\n",
       "origin_2         0\n",
       "origin_3         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg_df.dropna(inplace=True)\n",
    "mpg_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0, 0.1, 0.5, 1, 3, 5, 10, 100]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0, 0.1, 0.5, 1, 3, 5, 10, 100]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={'alpha': [0, 0.1, 0.5, 1, 3, 5, 10, 100]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data = mpg_df['mpg']\n",
    "feature_data = mpg_df[mpg_df.columns.difference(['mpg'])]\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, target_data, test_size=0.2, random_state=42)\n",
    "param = {'alpha':[0,0.1,0.5,1,3,5,10,100]}\n",
    "rigdemodel = Ridge()\n",
    "GrCv = GridSearchCV(rigdemodel, param,cv =5,scoring='neg_mean_squared_error')\n",
    "GrCv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "GrCv_df = pd.DataFrame(GrCv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>-8.536047</td>\n",
       "      <td>-7.608413</td>\n",
       "      <td>-10.152984</td>\n",
       "      <td>-5.705983</td>\n",
       "      <td>-12.756948</td>\n",
       "      <td>-8.952075</td>\n",
       "      <td>2.384737</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>-9.200776</td>\n",
       "      <td>-7.135029</td>\n",
       "      <td>-10.189644</td>\n",
       "      <td>-5.673744</td>\n",
       "      <td>-12.434933</td>\n",
       "      <td>-8.926825</td>\n",
       "      <td>2.356678</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>-9.168698</td>\n",
       "      <td>-7.173721</td>\n",
       "      <td>-10.274239</td>\n",
       "      <td>-5.718822</td>\n",
       "      <td>-12.033690</td>\n",
       "      <td>-8.873834</td>\n",
       "      <td>2.230572</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>-9.074155</td>\n",
       "      <td>-7.234377</td>\n",
       "      <td>-10.304923</td>\n",
       "      <td>-5.762636</td>\n",
       "      <td>-11.704691</td>\n",
       "      <td>-8.816157</td>\n",
       "      <td>2.119086</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>3</td>\n",
       "      <td>{'alpha': 3}</td>\n",
       "      <td>-8.889592</td>\n",
       "      <td>-7.500111</td>\n",
       "      <td>-10.413569</td>\n",
       "      <td>-5.888747</td>\n",
       "      <td>-11.085991</td>\n",
       "      <td>-8.755602</td>\n",
       "      <td>1.896978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.002147</td>\n",
       "      <td>5</td>\n",
       "      <td>{'alpha': 5}</td>\n",
       "      <td>-8.846106</td>\n",
       "      <td>-7.744125</td>\n",
       "      <td>-10.533270</td>\n",
       "      <td>-5.982942</td>\n",
       "      <td>-10.829104</td>\n",
       "      <td>-8.787109</td>\n",
       "      <td>1.798526</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>-8.924027</td>\n",
       "      <td>-8.257713</td>\n",
       "      <td>-10.845811</td>\n",
       "      <td>-6.185829</td>\n",
       "      <td>-10.586765</td>\n",
       "      <td>-8.960029</td>\n",
       "      <td>1.696654</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>-11.456261</td>\n",
       "      <td>-11.773078</td>\n",
       "      <td>-14.170603</td>\n",
       "      <td>-9.032860</td>\n",
       "      <td>-11.316220</td>\n",
       "      <td>-11.549804</td>\n",
       "      <td>1.631978</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.003235      0.003063         0.000669        0.000850           0   \n",
       "1       0.001527      0.002325         0.001405        0.002563         0.1   \n",
       "2       0.001514      0.001686         0.001786        0.001866         0.5   \n",
       "3       0.000240      0.000480         0.002908        0.003565           1   \n",
       "4       0.000504      0.000780         0.002130        0.002333           3   \n",
       "5       0.000602      0.001204         0.001709        0.002147           5   \n",
       "6       0.001657      0.003314         0.000000        0.000000          10   \n",
       "7       0.002097      0.002196         0.000301        0.000601         100   \n",
       "\n",
       "           params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0    {'alpha': 0}          -8.536047          -7.608413         -10.152984   \n",
       "1  {'alpha': 0.1}          -9.200776          -7.135029         -10.189644   \n",
       "2  {'alpha': 0.5}          -9.168698          -7.173721         -10.274239   \n",
       "3    {'alpha': 1}          -9.074155          -7.234377         -10.304923   \n",
       "4    {'alpha': 3}          -8.889592          -7.500111         -10.413569   \n",
       "5    {'alpha': 5}          -8.846106          -7.744125         -10.533270   \n",
       "6   {'alpha': 10}          -8.924027          -8.257713         -10.845811   \n",
       "7  {'alpha': 100}         -11.456261         -11.773078         -14.170603   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0          -5.705983         -12.756948        -8.952075        2.384737   \n",
       "1          -5.673744         -12.434933        -8.926825        2.356678   \n",
       "2          -5.718822         -12.033690        -8.873834        2.230572   \n",
       "3          -5.762636         -11.704691        -8.816157        2.119086   \n",
       "4          -5.888747         -11.085991        -8.755602        1.896978   \n",
       "5          -5.982942         -10.829104        -8.787109        1.798526   \n",
       "6          -6.185829         -10.586765        -8.960029        1.696654   \n",
       "7          -9.032860         -11.316220       -11.549804        1.631978   \n",
       "\n",
       "   rank_test_score  \n",
       "0                6  \n",
       "1                5  \n",
       "2                4  \n",
       "3                3  \n",
       "4                1  \n",
       "5                2  \n",
       "6                7  \n",
       "7                8  "
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GrCv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "릿지!\n",
      "best MSE: 8.76\n",
      "Ridge(alpha=3)\n",
      "최적 모델의 r2: 0.81\n",
      "최적 모델의 회귀계수 \n",
      "                      0\n",
      "acceleration  -0.548118\n",
      "cylinders_3   -2.795670\n",
      "cylinders_4    3.186188\n",
      "cylinders_5    0.015483\n",
      "cylinders_6   -0.587682\n",
      "cylinders_8    0.181681\n",
      "displacement   1.004750\n",
      "horsepower    -2.057450\n",
      "model year     2.186579\n",
      "model year_70  0.858705\n",
      "model year_71  1.162131\n",
      "model year_72 -0.344986\n",
      "model year_73 -1.414515\n",
      "model year_74 -0.454730\n",
      "model year_75 -1.298507\n",
      "model year_76 -1.225429\n",
      "model year_77 -0.505436\n",
      "model year_78 -1.307586\n",
      "model year_79  0.484101\n",
      "model year_80  2.799748\n",
      "model year_81  0.564698\n",
      "model year_82  0.681807\n",
      "origin_1      -1.336202\n",
      "origin_2       0.006177\n",
      "origin_3       1.330025\n",
      "weight        -3.063020\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('릿지!')\n",
    "print(f'best MSE: {-1*round(GrCv.best_score_,2)}')\n",
    "best_Rigde= GrCv.best_estimator_\n",
    "print(best_Rigde)\n",
    "y_pred = best_Rigde.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'최적 모델의 r2: {round(r2,2)}')\n",
    "print(f'최적 모델의 회귀계수 \\n{pd.DataFrame(best_Rigde.coef_,feature_data.columns)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4]Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  9.78\n",
      "최적 하이퍼 파라미터 : {'alpha': 0.01}\n",
      "\n",
      "r2 : 0.82\n",
      "최적 모델의 회귀 계수 \n",
      "                   coef\n",
      "weight        -3.691830\n",
      "cylinders_3   -1.811801\n",
      "horsepower    -1.804781\n",
      "origin_1      -1.645422\n",
      "model year_78 -1.112435\n",
      "model year_75 -1.052888\n",
      "model year_76 -1.016856\n",
      "model year_73 -0.867343\n",
      "model year_77 -0.595946\n",
      "acceleration  -0.343285\n",
      "cylinders_6   -0.335565\n",
      "model year_72 -0.000000\n",
      "model year_74 -0.000000\n",
      "cylinders_8    0.000000\n",
      "model year_81  0.000000\n",
      "origin_2       0.000000\n",
      "model year_79  0.172289\n",
      "model year_82  0.301727\n",
      "cylinders_5    0.648954\n",
      "origin_3       0.850093\n",
      "model year_71  1.599982\n",
      "model year_70  1.767567\n",
      "displacement   1.874972\n",
      "model year     2.759721\n",
      "cylinders_4    3.543360\n",
      "model year_80  4.147221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x199b8213520>,\n",
       "  <matplotlib.axis.XTick at 0x199b82134f0>,\n",
       "  <matplotlib.axis.XTick at 0x199b7e8c520>,\n",
       "  <matplotlib.axis.XTick at 0x199b81e4af0>,\n",
       "  <matplotlib.axis.XTick at 0x199b8267850>,\n",
       "  <matplotlib.axis.XTick at 0x199b82848b0>,\n",
       "  <matplotlib.axis.XTick at 0x199b82840d0>,\n",
       "  <matplotlib.axis.XTick at 0x199b8284970>,\n",
       "  <matplotlib.axis.XTick at 0x199b8289550>,\n",
       "  <matplotlib.axis.XTick at 0x199b8289d30>,\n",
       "  <matplotlib.axis.XTick at 0x199b8295550>,\n",
       "  <matplotlib.axis.XTick at 0x199b8295d30>,\n",
       "  <matplotlib.axis.XTick at 0x199b8295610>,\n",
       "  <matplotlib.axis.XTick at 0x199b8295be0>,\n",
       "  <matplotlib.axis.XTick at 0x199b829e700>,\n",
       "  <matplotlib.axis.XTick at 0x199b829eee0>,\n",
       "  <matplotlib.axis.XTick at 0x199b83b4700>,\n",
       "  <matplotlib.axis.XTick at 0x199b829e580>,\n",
       "  <matplotlib.axis.XTick at 0x199b82956d0>,\n",
       "  <matplotlib.axis.XTick at 0x199b829e940>,\n",
       "  <matplotlib.axis.XTick at 0x199b83c09d0>,\n",
       "  <matplotlib.axis.XTick at 0x199b83c0130>,\n",
       "  <matplotlib.axis.XTick at 0x199b83c0b50>,\n",
       "  <matplotlib.axis.XTick at 0x199b8289700>,\n",
       "  <matplotlib.axis.XTick at 0x199b83c7c10>,\n",
       "  <matplotlib.axis.XTick at 0x199b83d3430>],\n",
       " [Text(0, 0, 'weight'),\n",
       "  Text(1, 0, 'cylinders_3'),\n",
       "  Text(2, 0, 'horsepower'),\n",
       "  Text(3, 0, 'origin_1'),\n",
       "  Text(4, 0, 'model year_78'),\n",
       "  Text(5, 0, 'model year_75'),\n",
       "  Text(6, 0, 'model year_76'),\n",
       "  Text(7, 0, 'model year_73'),\n",
       "  Text(8, 0, 'model year_77'),\n",
       "  Text(9, 0, 'acceleration'),\n",
       "  Text(10, 0, 'cylinders_6'),\n",
       "  Text(11, 0, 'model year_72'),\n",
       "  Text(12, 0, 'model year_74'),\n",
       "  Text(13, 0, 'cylinders_8'),\n",
       "  Text(14, 0, 'model year_81'),\n",
       "  Text(15, 0, 'origin_2'),\n",
       "  Text(16, 0, 'model year_79'),\n",
       "  Text(17, 0, 'model year_82'),\n",
       "  Text(18, 0, 'cylinders_5'),\n",
       "  Text(19, 0, 'origin_3'),\n",
       "  Text(20, 0, 'model year_71'),\n",
       "  Text(21, 0, 'model year_70'),\n",
       "  Text(22, 0, 'displacement'),\n",
       "  Text(23, 0, 'model year'),\n",
       "  Text(24, 0, 'cylinders_4'),\n",
       "  Text(25, 0, 'model year_80')])"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('라쏘!')\n",
    "target_data = mpg_df['mpg']\n",
    "feature_data = mpg_df[mpg_df.columns.difference(['mpg'])]\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, target_data, test_size=0.2, random_state=52)\n",
    "param = {'alpha': [0.001, 0.01, 0.1, 1,3,5, 10, 100]}\n",
    "ls_model = Lasso()\n",
    "GsCv_ls = GridSearchCV(estimator=ls_model, param_grid=param, scoring='neg_mean_squared_error',cv = 5,refit = True)\n",
    "GsCv_ls.fit(X_train, y_train)\n",
    "print('MSE : ',round(-1*GsCv_ls.best_score_,2))\n",
    "print(f'최적 하이퍼 파라미터 : {GsCv_ls.best_params_}')\n",
    "best_lasso_model = GsCv_ls.best_estimator_\n",
    "print()\n",
    "\n",
    "y_pred = best_lasso_model.predict(X_test)\n",
    "r2  = r2_score(y_test, y_pred)\n",
    "print(f'r2 : {round(r2,2)}')\n",
    "lasso_coef_df= pd.DataFrame(best_lasso_model.coef_,feature_data.columns,columns=['coef'])\n",
    "lasso_coef_df.sort_values(by='coef',inplace=True)\n",
    "print(f'최적 모델의 회귀 계수 \\n{lasso_coef_df}')\n",
    "\n",
    "plt.bar(range(len(lasso_coef_df)), lasso_coef_df['coef'])\n",
    "#plt.text(range(len(lasso_coef_df)),y= 0, lasso_coef_df.index)\n",
    "plt.xticks(range(len(lasso_coef_df)), lasso_coef_df.index, rotation=90)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과\n",
    "- 가장 낮은 MSE를 갖으며 높은 R2를 가진 모델은 lasso모델\n",
    "- 해당 최적 하이퍼파라미터는 alpha 0.01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀\n",
    "- target: origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "300 fits failed out of a total of 540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\dddf\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.64741423        nan        nan        nan 0.64741423\n",
      " 0.70512033 0.64741423 0.70512033 0.67613927 0.67613927 0.65376344\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.64741423        nan        nan        nan 0.65376344\n",
      " 0.71167435 0.64101382 0.71167435 0.71157194 0.6859191  0.6764977\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.69559652        nan        nan        nan 0.68602151\n",
      " 0.72462878 0.68632873 0.71495136 0.70860215 0.70542755 0.69262673\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.74357399        nan        nan        nan 0.69897593\n",
      " 0.73082437 0.73399898 0.72114695 0.71162314 0.70517153 0.68929852\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.74362519        nan        nan        nan 0.68934972\n",
      " 0.74357399 0.73405018 0.73712238 0.73082437 0.68914491 0.68929852\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.7499744         nan        nan        nan 0.68612391\n",
      " 0.74050179 0.7467998  0.73712238 0.7499744  0.69231951 0.68607271\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.749974398361495"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모듈 로딩\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#데이터 불러오기\n",
    "mpg = pd.read_csv('../dataset/auto-mpg.csv')\n",
    "mpg.rename(columns={'car name': 'car_name'}, inplace=True)\n",
    "mpg['origin'] = mpg['origin'].astype('category')\n",
    "\n",
    "\n",
    "#같은 차종의 마력의 평균으로 '?'대체\n",
    "ques_car_name=mpg[mpg['horsepower']== '?'].car_name\n",
    "mean_list=[]\n",
    "\n",
    "x1 = mpg[mpg['car_name']==ques_car_name.iloc[0]].horsepower[1:].astype('int').mean()\n",
    "x2 = mpg[mpg['car_name']==ques_car_name.iloc[1]].horsepower[mpg[mpg['car_name']==ques_car_name.iloc[1]].horsepower != '?'].astype('int').mean()\n",
    "mpg.loc[32,'horsepower']= x1\n",
    "mpg.loc[126,'horsepower']=x2\n",
    "mpg.drop(mpg[mpg['horsepower']=='?'].index, inplace=True)\n",
    "mpg['horsepower'].value_counts()\n",
    "mpg['horsepower'] = mpg['horsepower'].astype('int64')\n",
    "#\n",
    "\n",
    "\n",
    "#데이터 표준화\n",
    "ss_data = StandardScaler()\n",
    "mpg_df = ss_data.fit_transform(mpg[mpg.columns[1:-2]])\n",
    "mpg_df = pd.DataFrame(mpg_df,columns=mpg.columns[1:-2])\n",
    "mpg_df = pd.concat([mpg_df, mpg[['mpg','origin']]], axis=1)\n",
    "mpg_df\n",
    "#데이터 결측치 제거\n",
    "mpg_df.dropna(inplace=True)\n",
    "mpg_df.isnull().sum()\n",
    "\n",
    "#더미데이터 생성\n",
    "model_year = pd.get_dummies(mpg['model year'], prefix='model year')\n",
    "cylinders = pd.get_dummies(mpg['cylinders'], prefix='cylinders')\n",
    "mpg_df = pd.concat([mpg_df, cylinders], axis=1)\n",
    "mpg_df = pd.concat([mpg_df, model_year], axis=1)\n",
    "\n",
    "#데이터 결측치 제거\n",
    "mpg_df.dropna(inplace=True)\n",
    "mpg_df.isnull().sum()\n",
    "mpg_df.columns\n",
    "# #데이터 분석\n",
    "\n",
    "target_data = mpg_df['origin']\n",
    "feature_data = mpg_df[mpg_df.columns.difference(['origin'])]\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, target_data, test_size=0.2, random_state=60)\n",
    "LR = LogisticRegression()\n",
    "GsCv_lr = GridSearchCV(LR, param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2', 'elasticnet'], 'solver':['lbfgs','liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']},cv=5, refit=True)\n",
    "GsCv_lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100, penalty='l1', solver='liblinear')\n",
      "LR Accuracy Score:  0.73\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-6.000e-02, -4.840e+00, -2.460e+00,  3.300e+00, -1.240e+00,\n",
       "         6.670e+00,  1.647e+01,  7.550e+00, -1.380e+00,  1.000e-02,\n",
       "        -1.160e+00, -9.000e-02, -7.500e-01, -1.380e+00,  0.000e+00,\n",
       "        -1.500e-01,  4.800e-01,  1.150e+00,  9.500e-01,  3.000e+00,\n",
       "         8.900e-01,  2.830e+00,  2.850e+00, -3.500e-01, -3.580e+00],\n",
       "       [-7.200e-01,  2.970e+00, -6.500e+00,  0.000e+00,  4.330e+00,\n",
       "        -3.150e+00, -8.160e+00, -9.510e+00, -9.700e-01, -7.700e-01,\n",
       "        -1.400e-01,  0.000e+00, -5.700e-01,  1.310e+00, -5.300e-01,\n",
       "        -3.400e-01,  7.000e-02,  1.500e-01,  1.000e-02, -1.600e-01,\n",
       "         3.000e-01, -2.180e+00, -9.800e-01,  5.000e-02,  5.650e+00],\n",
       "       [ 4.600e-01,  1.410e+00,  7.100e+00, -9.800e-01, -3.920e+00,\n",
       "        -1.390e+00, -8.440e+00, -6.700e-01,  1.750e+00,  1.630e+00,\n",
       "         1.290e+00,  3.800e-01,  1.420e+00,  0.000e+00,  1.200e-01,\n",
       "         9.000e-02, -1.280e+00, -1.950e+00, -1.880e+00, -4.430e+00,\n",
       "        -3.010e+00, -3.400e+00, -4.220e+00,  2.000e-01, -1.530e+00]])"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(GsCv_lr.best_estimator_)\n",
    "best_lr_model = GsCv_lr.best_estimator_\n",
    "y_pred = best_lr_model.predict(X_test)\n",
    "#lr_roc_auc_score = roc_auc_score(y_test, y_pred)\n",
    "accuary = accuracy_score(y_test, y_pred)\n",
    "#print(\"LR ROC AUC Score: \", lr_roc_auc_score)\n",
    "print(\"LR Accuracy Score: \", round(accuary,2))\n",
    "#회귀 계수\n",
    "np.round(best_lr_model.coef_,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
